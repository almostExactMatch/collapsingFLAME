{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 17.5})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rc('axes.formatter', useoffset=False)\n",
    "\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.append( os.path.abspath(os.path.join( os.path.dirname('..') , os.path.pardir )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import FLAME with reuse of control units\n",
    "from colFLAMEbit_c import *\n",
    "from FLAMEbit_c import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_sec_order(arr):\n",
    "    ''' an intermediate data generation function used \n",
    "        for generating second order information '''\n",
    "    \n",
    "    second_order_feature = []\n",
    "    num_cov_sec = len(arr[0])\n",
    "    for a in arr:\n",
    "        tmp = []\n",
    "        for i in range(num_cov_sec):\n",
    "            for j in range(i+1, num_cov_sec):\n",
    "                tmp.append( a[i] * a[j] )\n",
    "        second_order_feature.append(tmp)\n",
    "        \n",
    "    return np.array(second_order_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generation_hybrid(num_control, num_treated, num_cov, exponential = True):\n",
    "    \n",
    "    # a data generation function, not used here\n",
    "    \n",
    "    xc = np.random.binomial(1, 0.5, size=(num_control, num_cov))   # data for conum_treatedrol group\n",
    "    xt = np.random.binomial(1, 0.5, size=(num_treated, num_cov))   # data for treatmenum_treated group\n",
    "        \n",
    "    errors1 = np.random.normal(0, 0.05, size=num_control)    # some noise\n",
    "    errors2 = np.random.normal(0, 0.05, size=num_treated)    # some noise\n",
    "    \n",
    "    #dense_bs_sign = np.random.choice([-1,1], num_cov_dense)\n",
    "    if exponential:\n",
    "        dense_bs = [ 20.*((4./5)**(i+1)) for i in range(num_cov) ]\n",
    "    else:\n",
    "        dense_bs = [ (20./(i+1)) for i in range(num_cov) ]\n",
    "\n",
    "    yc = np.dot(xc, np.array(dense_bs)) #+ errors1     # y for control group \n",
    "\n",
    "    # y for treated group \n",
    "    treatment_eff_coef = np.random.normal( 1.5, 0.05, size=num_cov) #beta\n",
    "    treatment_effect = np.dot(xt, treatment_eff_coef) \n",
    "    \n",
    "    yt = np.dot(xt,np.array(dense_bs))+treatment_effect \n",
    "                                      # + errors2    \n",
    "        \n",
    "    df1 = pd.DataFrame(np.hstack([xc]), \n",
    "                       columns=range(num_cov))\n",
    "    df1['outcome'] = yc\n",
    "    df1['treated'] = 0\n",
    "\n",
    "    df2 = pd.DataFrame(np.hstack([xt]), \n",
    "                       columns=range(num_cov ) ) \n",
    "    df2['outcome'] = yt\n",
    "    df2['treated'] = 1\n",
    "\n",
    "    df = pd.concat([df1,df2])\n",
    "    df['matched'] = 0\n",
    "  \n",
    "    return df, dense_bs, treatment_eff_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation, set exponential to be True or False for exponential decay and power-law decay respectively\n",
    "\n",
    "d = data_generation_hybrid(40000, 2000, 18, exponential=True)\n",
    "df = d[0] \n",
    "holdout,_,_ = data_generation_hybrid(40000, 2000, 18, exponential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#------- EXPERIMENT 1:RATIO 1 -----------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the dataframe with different ratio of treatments/controls\n",
    "df1 = df.iloc[20000:42000,:] \n",
    "df2 = df.iloc[30000:42000,:] \n",
    "holdout1 = holdout.iloc[20000:42000,:] \n",
    "holdout2 = holdout.iloc[30000:42000,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "-0.974467791601\n",
      "1460\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "-1.96349141636\n",
      "1082\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "-3.15532875899\n",
      "578\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "-4.37367651093\n",
      "156\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "-5.91597205422\n",
      "21\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "-8.32306463632\n",
      "0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "no more matches\n"
     ]
    }
   ],
   "source": [
    "res_gen = run_bit(df, holdout, range(18), [2]*18, threshold = -10, tradeoff_param = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714\n",
      "1460\n",
      "1246\n",
      "1078\n",
      "924\n",
      "782\n",
      "670\n",
      "566\n",
      "475\n",
      "410\n",
      "344\n",
      "300\n",
      "252\n",
      "219\n",
      "178\n",
      "156\n",
      "141\n",
      "118\n",
      "96\n",
      "77\n",
      "62\n",
      "50\n",
      "46\n",
      "42\n",
      "38\n",
      "34\n",
      "27\n",
      "23\n",
      "21\n",
      "17\n",
      "15\n",
      "10\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "no more matches\n"
     ]
    }
   ],
   "source": [
    "res = run_mpbit(df, holdout, range(18), [2]*18, threshold =-10, tradeoff_param = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(res_gen, open('413gen-ratio1', 'wb'))\n",
    "pickle.dump(res, open('413col-ratio1', 'wb'))\n",
    "pickle.dump(d, open('413data-ratio1', 'wb'))\n",
    "\n",
    "df.to_csv(\"413dataratio1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ground_truth( eff_coef, covs_ordered, num_covs_dense = 18, num_second_order = 0, second_order = True):\n",
    "    arr = np.array(list(itertools.product([0,1], repeat=num_covs_dense)))\n",
    "    effect = np.dot(arr, eff_coef)\n",
    "    if second_order:\n",
    "        second_effect = np.sum(construct_sec_order(arr[:,:num_second_order] ), axis=1)\n",
    "        effect = effect + second_effect\n",
    "    df = pd.DataFrame(arr, columns=covs_ordered)\n",
    "    df['effect'] = effect\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth(d[2], list(range(18)), num_covs_dense = 18, num_second_order = 0, second_order = False)\n",
    "\n",
    "ground_truth.to_csv(\"413groundtruthratio1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_list = []\n",
    "pred_list = []\n",
    "count = 0\n",
    "av_err_cate = []\n",
    "aux_size = []\n",
    "for r in res[1]:\n",
    "    count = count +1\n",
    "    tmp = pd.merge(r, ground_truth, on = list(set(range(18)) & set(r.columns) ), how = 'left')\n",
    "    truth_list = truth_list + list(tmp['effect_y'])\n",
    "    pred_list = pred_list + list(tmp['effect_x'])\n",
    "    aux_size = aux_size + list(tmp['size'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the lists of true and estimated cates for genFLAME\n",
    "\n",
    "truth_list_gen = []\n",
    "pred_list_gen = []\n",
    "\n",
    "aux_size_gen = []\n",
    "av_err_cate_gen = []\n",
    "for r_gen in res_gen[1]:\n",
    "    tmp_gen = pd.merge(r_gen, ground_truth, on = list(set(range(18)) & set(r_gen.columns) ), how = 'left')\n",
    "    truth_list_gen = truth_list_gen + list(tmp_gen['effect_y'])\n",
    "    pred_list_gen = pred_list_gen + list(tmp_gen['effect_x'])\n",
    "    aux_size_gen = aux_size_gen + list(tmp_gen['size'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the true and estimated cates : \n",
    "\n",
    "\n",
    "effect_col = pd.DataFrame()\n",
    "effect_col['pred'] = pred_list\n",
    "effect_col['true'] = truth_list\n",
    "effect_col['size'] = aux_size\n",
    "\n",
    "effect_col['method'] = ['collapsing FLAME']*len(truth_list)\n",
    "\n",
    "effect_gen = pd.DataFrame()\n",
    "effect_gen['pred'] = pred_list_gen\n",
    "effect_gen['true'] = truth_list_gen\n",
    "effect_gen['method'] = ['generic FLAME']*len(truth_list_gen)\n",
    "effect_gen['size'] = aux_size_gen\n",
    "\n",
    "\n",
    "effect = pd.concat([effect_gen, effect_col])\n",
    "#effect_gen.to_csv('effect_gen.csv')\n",
    "\n",
    "effect_col.to_csv('effect413col_ratio1.csv')\n",
    "\n",
    "effect_gen.to_csv('effect413gen_ratio1.csv')\n",
    "\n",
    "effect.to_csv('effect413_ratio1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(x=\"true\", y=\"pred\",hue=\"method\", data = effect, fit_reg=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------Ratio2---#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "-0.974566384023\n",
      "1719\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "-1.96419333275\n",
      "1499\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "-3.15602338887\n",
      "1106\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "-4.37309878157\n",
      "579\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "-5.91744665272\n",
      "163\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "-8.31804840249\n",
      "19\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "-10.9958662654\n",
      "0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "no more matches\n"
     ]
    }
   ],
   "source": [
    "res_gen1 = run_bit(df1, holdout1, range(18), [2]*18, threshold =-10, tradeoff_param = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1857\n",
      "1719\n",
      "1602\n",
      "1470\n",
      "1358\n",
      "1255\n",
      "1172\n",
      "1073\n",
      "990\n",
      "910\n",
      "847\n",
      "782\n",
      "725\n",
      "669\n",
      "619\n",
      "586\n",
      "541\n",
      "494\n",
      "458\n",
      "412\n",
      "379\n",
      "349\n",
      "322\n",
      "300\n",
      "283\n",
      "265\n",
      "242\n",
      "229\n",
      "218\n",
      "201\n",
      "189\n",
      "171\n",
      "156\n",
      "149\n",
      "136\n",
      "132\n",
      "122\n",
      "112\n",
      "102\n",
      "91\n",
      "88\n",
      "83\n",
      "74\n",
      "69\n",
      "62\n",
      "56\n",
      "54\n",
      "46\n",
      "41\n",
      "36\n",
      "35\n",
      "32\n",
      "30\n",
      "28\n",
      "24\n",
      "18\n",
      "18\n",
      "17\n",
      "15\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "no more matches\n"
     ]
    }
   ],
   "source": [
    "res1 = run_mpbit(df1, holdout1, range(18), [2]*18, threshold = -10, tradeoff_param = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(res_gen1, open('413gen-ratio2', 'wb'))\n",
    "pickle.dump(res1, open('413col-ratio2', 'wb'))\n",
    "\n",
    "df1.to_csv(\"413dataratio2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truth_list1 = []\n",
    "pred_list1 = []\n",
    "count = 0\n",
    "av_err_cate = []\n",
    "aux_size1 = []\n",
    "for r in res1[1]:\n",
    "    count = count +1\n",
    "    tmp1 = pd.merge(r, ground_truth, on = list(set(range(18)) & set(r.columns) ), how = 'left')\n",
    "    truth_list1 = truth_list1 + list(tmp1['effect_y'])\n",
    "    pred_list1 = pred_list1 + list(tmp1['effect_x'])\n",
    "    aux_size1 = aux_size1 + list(tmp1['size'])\n",
    "\n",
    "\n",
    "truth_list_gen1 = []\n",
    "pred_list_gen1 = []\n",
    "\n",
    "aux_size_gen1 = []\n",
    "av_err_cate_gen1 = []\n",
    "for r_gen in res_gen1[1]:\n",
    "    tmp_gen1 = pd.merge(r_gen, ground_truth, on = list(set(range(18)) & set(r_gen.columns) ), how = 'left')\n",
    "    truth_list_gen1 = truth_list_gen1 + list(tmp_gen1['effect_y'])\n",
    "    pred_list_gen1 = pred_list_gen1 + list(tmp_gen1['effect_x'])\n",
    "    aux_size_gen1 = aux_size_gen1 + list(tmp_gen1['size'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the true and estimated cates : \n",
    "\n",
    "effect_col1 = pd.DataFrame()\n",
    "effect_col1['pred'] = pred_list1\n",
    "effect_col1['true'] = truth_list1\n",
    "effect_col1['size'] = aux_size1\n",
    "\n",
    "effect_col1['method'] = ['collapsing FLAME']*len(truth_list1)\n",
    "\n",
    "\n",
    "#effect_col.to_csv('effect.csv')\n",
    "\n",
    "effect_gen1 = pd.DataFrame()\n",
    "effect_gen1['pred'] = pred_list_gen1\n",
    "effect_gen1['true'] = truth_list_gen1\n",
    "effect_gen1['method'] = ['generic FLAME']*len(truth_list_gen1)\n",
    "effect_gen1['size'] = aux_size_gen1\n",
    "\n",
    "\n",
    "effect1 = pd.concat([effect_gen1, effect_col1])\n",
    "\n",
    "\n",
    "effect_col1.to_csv('effect413col_ratio2.csv')\n",
    "\n",
    "effect_gen1.to_csv('effect413gen_ratio2.csv')\n",
    "\n",
    "effect1.to_csv('effect413_ratio2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(x=\"true\", y=\"pred\",hue=\"method\", data = effect1, fit_reg=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--RATIO3---#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "-0.974696177791\n",
      "1845\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "-1.96383269351\n",
      "1719\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "-3.15490115698\n",
      "1485\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "-4.3725634571\n",
      "1108\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "-5.91487081324\n",
      "604\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "-8.32286640009\n",
      "180\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "-11.0118542525\n",
      "30\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "-14.4531214798\n",
      "0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "no more matches\n"
     ]
    }
   ],
   "source": [
    "res_gen2 = run_bit(df2, holdout2, range(18), [2]*18, threshold =-10, tradeoff_param = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919\n",
      "1845\n",
      "1778\n",
      "1701\n",
      "1638\n",
      "1578\n",
      "1524\n",
      "1464\n",
      "1415\n",
      "1358\n",
      "1314\n",
      "1262\n",
      "1221\n",
      "1177\n",
      "1123\n",
      "1080\n",
      "1040\n",
      "1006\n",
      "968\n",
      "933\n",
      "903\n",
      "858\n",
      "825\n",
      "797\n",
      "770\n",
      "742\n",
      "712\n",
      "692\n",
      "665\n",
      "648\n",
      "628\n",
      "598\n",
      "571\n",
      "558\n",
      "541\n",
      "524\n",
      "507\n",
      "493\n",
      "469\n",
      "455\n",
      "445\n",
      "430\n",
      "412\n",
      "400\n",
      "383\n",
      "367\n",
      "358\n",
      "339\n",
      "332\n",
      "314\n",
      "304\n",
      "295\n",
      "288\n",
      "275\n",
      "263\n",
      "253\n",
      "243\n",
      "236\n",
      "225\n",
      "213\n",
      "200\n",
      "190\n",
      "180\n",
      "169\n",
      "163\n",
      "155\n",
      "151\n",
      "144\n",
      "137\n",
      "132\n",
      "128\n",
      "121\n",
      "117\n",
      "111\n",
      "108\n",
      "102\n",
      "95\n",
      "92\n",
      "88\n",
      "85\n",
      "83\n",
      "81\n",
      "77\n",
      "74\n",
      "72\n",
      "72\n",
      "72\n",
      "70\n",
      "68\n",
      "66\n",
      "63\n",
      "61\n",
      "61\n",
      "58\n",
      "56\n",
      "55\n",
      "51\n",
      "50\n",
      "48\n",
      "47\n",
      "43\n",
      "42\n",
      "41\n",
      "41\n",
      "41\n",
      "40\n",
      "39\n",
      "37\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "34\n",
      "33\n",
      "31\n",
      "31\n",
      "29\n",
      "29\n",
      "28\n",
      "26\n",
      "26\n",
      "25\n",
      "24\n",
      "24\n",
      "23\n",
      "20\n",
      "20\n",
      "19\n",
      "19\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "17\n",
      "17\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "13\n",
      "13\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "no more matches\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res2 = run_mpbit(df2, holdout2, range(18), [2]*18, threshold = -10, tradeoff_param = 0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(res_gen2, open('413gen-ratio3', 'wb'))\n",
    "pickle.dump(res2, open('413col-ratio3', 'wb'))\n",
    "\n",
    "df2.to_csv(\"413dataratio3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truth_list2 = []\n",
    "pred_list2 = []\n",
    "count = 0\n",
    "av_err_cate = []\n",
    "aux_size2 = []\n",
    "for r in res2[1]:\n",
    "    count = count +1\n",
    "    tmp2 = pd.merge(r, ground_truth, on = list(set(range(18)) & set(r.columns) ), how = 'left')\n",
    "    truth_list2 = truth_list2 + list(tmp2['effect_y'])\n",
    "    pred_list2 = pred_list2 + list(tmp2['effect_x'])\n",
    "    aux_size2 = aux_size2 + list(tmp2['size'])\n",
    "\n",
    "\n",
    "truth_list_gen2 = []\n",
    "pred_list_gen2 = []\n",
    "\n",
    "aux_size_gen2 = []\n",
    "for r_gen in res_gen2[1]:\n",
    "    tmp_gen2 = pd.merge(r_gen, ground_truth, on = list(set(range(18)) & set(r_gen.columns) ), how = 'left')\n",
    "    truth_list_gen2 = truth_list_gen2 + list(tmp_gen2['effect_y'])\n",
    "    pred_list_gen2 = pred_list_gen2 + list(tmp_gen2['effect_x'])\n",
    "    aux_size_gen2 = aux_size_gen2 + list(tmp_gen2['size'])\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a dataframe with the true and estimated cates : \n",
    "\n",
    "\n",
    "effect_col2 = pd.DataFrame()\n",
    "effect_col2['pred'] = pred_list2\n",
    "effect_col2['true'] = truth_list2\n",
    "effect_col2['size'] = aux_size2\n",
    "\n",
    "effect_col2['method'] = ['collapsing FLAME']*len(truth_list2)\n",
    "\n",
    "effect_gen2 = pd.DataFrame()\n",
    "effect_gen2['pred'] = pred_list_gen2\n",
    "effect_gen2['true'] = truth_list_gen2\n",
    "effect_gen2['method'] = ['generic FLAME']*len(truth_list_gen2)\n",
    "effect_gen2['size'] = aux_size_gen2\n",
    "\n",
    "\n",
    "effect2 = pd.concat([effect_gen2, effect_col2])\n",
    "\n",
    "\n",
    "effect_col2.to_csv('effect413col_ratio3.csv')\n",
    "\n",
    "effect_gen2.to_csv('effect413gen_ratio3.csv')\n",
    "\n",
    "effect2.to_csv('effect413_ratio3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(x=\"true\", y=\"pred\",hue=\"method\", data = effect2, fit_reg=False)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 17.5})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rc('axes.formatter', useoffset=False)\n",
    "\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.append( os.path.abspath(os.path.join( os.path.dirname('..') , os.path.pardir )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from colFLAMEbit_imp import *\n",
    "from FLAMEbit_imp import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_sec_order(arr):\n",
    "    ''' an intermediate data generation function used \n",
    "        for generating second order information '''\n",
    "    \n",
    "    second_order_feature = []\n",
    "    num_cov_sec = len(arr[0])\n",
    "    for a in arr:\n",
    "        tmp = []\n",
    "        for i in range(num_cov_sec):\n",
    "            for j in range(i+1, num_cov_sec):\n",
    "                tmp.append( a[i] * a[j] )\n",
    "        second_order_feature.append(tmp)\n",
    "        \n",
    "    return np.array(second_order_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generation_dense_2(num_control, num_treated, num_cov_dense, \n",
    "                            num_covs_unimportant, control_m = 0.1,\n",
    "                            treated_m = 0.9):\n",
    "    \n",
    "    ''' the data generating function that we will use; \n",
    "        includes second order information '''\n",
    "    \n",
    "\n",
    "    # generate data for control group \n",
    "    xc = np.random.binomial(1, 0.5, size=(num_control, num_cov_dense)) #bernouilli\n",
    "    \n",
    "    # generate data for treated group \n",
    "    xt = np.random.binomial(1, 0.5, size=(num_treated, num_cov_dense))   #bernouilli\n",
    "     \n",
    "    \n",
    "    errors1 = np.random.normal(0, 0.1, size=num_control)    # some noise\n",
    "    \n",
    "    errors2 = np.random.normal(0, 0.1, size=num_treated)    # some noise\n",
    "    \n",
    "    dense_bs_sign = np.random.choice([-1,1], num_cov_dense) \n",
    "    \n",
    "    dense_bs = [ np.random.normal(s * 10, 1) for s in dense_bs_sign ]   #alpha in the paper\n",
    "\n",
    "    # y for control group \n",
    "    yc = np.dot(xc, np.array(dense_bs)) #+ errors1     \n",
    "       \n",
    "    # y for treated group \n",
    "    treatment_eff_coef = np.random.normal( 1.5, 0.15, size=num_cov_dense) #beta\n",
    "    treatment_effect = np.dot(xt, treatment_eff_coef) \n",
    "    \n",
    "    second = construct_sec_order(xt[:,:(num_covs_unimportant -1)])\n",
    "    treatment_eff_sec = np.sum(second, axis=1)\n",
    "    \n",
    "    yt = np.dot(xt,np.array(dense_bs))+treatment_effect+treatment_eff_sec \n",
    "                                      # + errors2    \n",
    "\n",
    "    # generate unimportant covariates for control group\n",
    "    xc2 = np.random.binomial(1, control_m, size=(num_control,\n",
    "                                                 num_covs_unimportant))  \n",
    "    \n",
    "    # generate unimportant covariates for treated group\n",
    "    xt2 = np.random.binomial(1, treated_m, size=(num_treated,\n",
    "                                                 num_covs_unimportant))   \n",
    "        \n",
    "    df1 = pd.DataFrame(np.hstack([xc, xc2]), \n",
    "                       columns=range(num_cov_dense + num_covs_unimportant))\n",
    "    df1['outcome'] = yc\n",
    "    df1['treated'] = 0\n",
    "\n",
    "    df2 = pd.DataFrame(np.hstack([xt, xt2]), \n",
    "                       columns=range(num_cov_dense + num_covs_unimportant)) \n",
    "    df2['outcome'] = yt\n",
    "    df2['treated'] = 1\n",
    "\n",
    "    df = pd.concat([df1,df2])\n",
    "    df['matched'] = 0\n",
    "  \n",
    "    return df, dense_bs, treatment_eff_coef\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation, set exponential to be True or False for exponential decay and power-law decay respectively\n",
    "\n",
    "d = data_generation_dense_2(15000, 15000, 5,10, control_m = 0.1, treated_m = 0.9)\n",
    "df = d[0] \n",
    "holdout,_,_ = data_generation_dense_2(15000, 15000, 5,10, control_m = 0.1, treated_m = 0.9)\n",
    "d[0].to_csv('411datatest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "30000\n",
      "-0.628990376615\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14]\n",
      "29998\n",
      "-0.628782900344\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "29987\n",
      "-0.628605267889\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 11, 13, 14]\n",
      "29949\n",
      "-0.628490239289\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 11, 14]\n",
      "29757\n",
      "-0.628391355151\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 14]\n",
      "29182\n",
      "-0.628317102461\n",
      "[0, 1, 2, 3, 4, 5, 6, 9, 14]\n",
      "28374\n",
      "-0.628239176364\n",
      "[0, 1, 2, 3, 4, 6, 9, 14]\n",
      "26756\n",
      "-0.628132027552\n",
      "[0, 1, 2, 3, 4, 6, 9]\n",
      "24089\n",
      "-0.628032096417\n",
      "[0, 1, 2, 3, 4, 6]\n",
      "19720\n",
      "-0.626789377156\n",
      "[0, 1, 2, 3, 4]\n",
      "4051\n",
      "-30.1797291638\n",
      "[0, 2, 3, 4]\n",
      "2610\n",
      "-72.6764381408\n",
      "[0, 2, 3]\n",
      "2610\n",
      "-126.653838152\n",
      "[0, 3]\n",
      "2610\n",
      "-206.953103053\n"
     ]
    }
   ],
   "source": [
    "#run generic flame til end\n",
    "\n",
    "res_gen = run_bit(df, holdout, range(15), [2]*15, covs_unimportant = -10, threshold = -10, tradeoff_param = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no more matches\n"
     ]
    }
   ],
   "source": [
    "# run collapsing flame til end\n",
    "\n",
    "res = run_mpbit(df, holdout, range(15), [2]*15, covs_unimportant=-10, threshold =-10, tradeoff_param = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data and result from gen and col FLAME to compare to other methods\n",
    "pickle.dump(res_gen, open('411genendrestest', 'wb'))\n",
    "pickle.dump(res, open('411colendrestest', 'wb'))\n",
    "pickle.dump(d, open('411datatest', 'wb'))\n",
    "\n",
    "d[0].to_csv('411data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a ground truth\n",
    "def ground_truth( eff_coef, covs_ordered, num_covs_dense = 5, num_second_order = 10, second_order = True):\n",
    "    arr = np.array(list(itertools.product([0,1], repeat=num_covs_dense)))\n",
    "    effect = np.dot(arr, eff_coef)\n",
    "    if second_order:\n",
    "        second_effect = np.sum(construct_sec_order(arr[:,:num_second_order] ), axis=1)\n",
    "        effect = effect + second_effect\n",
    "    df = pd.DataFrame(arr, columns=covs_ordered)\n",
    "    df['effect'] = effect\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate grouth truth data\n",
    "ground_truth = ground_truth(d[2], list(range(5)), num_covs_dense = 5, num_second_order = 10, second_order = True)\n",
    "ground_truth.to_csv('411groundtruthtest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true and estimated cates for matched units\n",
    "truth_list = []\n",
    "pred_list = []\n",
    "count = 0\n",
    "av_err_cate = []\n",
    "aux_size = []\n",
    "for r in res[1]:\n",
    "    count = count +1\n",
    "    tmp = pd.merge(r, ground_truth, on = list(set(range(5)) & set(r.columns) ), how = 'left')\n",
    "    truth_list = truth_list + list(tmp['effect_y'])\n",
    "    pred_list = pred_list + list(tmp['effect_x'])\n",
    "    aux_size = aux_size + list(tmp['size'])\n",
    "\n",
    "\n",
    "truth_list_gen = []\n",
    "pred_list_gen = []\n",
    "\n",
    "aux_size_gen = []\n",
    "av_err_cate_gen = []\n",
    "for r_gen in res_gen[1]:\n",
    "    tmp_gen = pd.merge(r_gen, ground_truth, on = list(set(range(5)) & set(r_gen.columns) ), how = 'left')\n",
    "    truth_list_gen = truth_list_gen + list(tmp_gen['effect_y'])\n",
    "    pred_list_gen = pred_list_gen + list(tmp_gen['effect_x'])\n",
    "    aux_size_gen = aux_size_gen + list(tmp_gen['size'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the true and estimated cates : data to be used in R for plots\n",
    "\n",
    "cateDF1 = pd.DataFrame()\n",
    "cateDF1['effect'] = pred_list\n",
    "cateDF1['cate'] = ['estimated']*len(pred_list)\n",
    "cateDF1['method'] = ['collapsing FLAME']*len(pred_list)\n",
    "\n",
    "\n",
    "cateDF2 = pd.DataFrame()\n",
    "cateDF2['effect'] = truth_list\n",
    "cateDF2['cate'] = ['true']*len(truth_list)\n",
    "cateDF2['method'] = ['collapsing FLAME']*len(truth_list)\n",
    "\n",
    "cateDF3 = pd.DataFrame()\n",
    "cateDF3['effect'] = pred_list_gen\n",
    "cateDF3['cate'] = ['estimated']*len(pred_list_gen)\n",
    "cateDF3['method'] = ['generic FLAME']*len(pred_list_gen)\n",
    "\n",
    "\n",
    "cateDF4 = pd.DataFrame()\n",
    "cateDF4['effect'] = truth_list_gen\n",
    "cateDF4['cate'] = ['true']*len(truth_list_gen)\n",
    "cateDF4['method'] = ['generic FLAME']*len(truth_list_gen)\n",
    "\n",
    "cate = pd.concat([cateDF1, cateDF2, cateDF3, cateDF4])\n",
    "cate_col = pd.concat([cateDF1, cateDF2])\n",
    "cate_gen = pd.concat([cateDF3, cateDF4])\n",
    "\n",
    "cate_gen.to_csv('cate411genend.csv')\n",
    "cate_col.to_csv('cate411colend.csv')\n",
    "\n",
    "cate.to_csv('cate411end.csv')\n",
    "\n",
    "\n",
    "\n",
    "effect_col = pd.DataFrame()\n",
    "effect_col['pred'] = pred_list\n",
    "effect_col['true'] = truth_list\n",
    "effect_col['size'] = aux_size\n",
    "\n",
    "effect_col['method'] = ['collapsing FLAME']*len(truth_list)\n",
    "\n",
    "\n",
    "effect_col.to_csv('effect411endcol.csv')\n",
    "\n",
    "effect_gen = pd.DataFrame()\n",
    "effect_gen['pred'] = pred_list_gen\n",
    "effect_gen['true'] = truth_list_gen\n",
    "effect_gen['method'] = ['generic FLAME']*len(truth_list_gen)\n",
    "effect_gen['size'] = aux_size_gen\n",
    "\n",
    "\n",
    "effect = pd.concat([effect_gen, effect_col])\n",
    "effect_gen.to_csv('effect411endgen.csv')\n",
    "\n",
    "effect.to_csv('effect411end.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------- early stopping----------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run generic flame before dropping important covariates\n",
    "res_genearly = run_bit(df, holdout, range(15), [2]*15, covs_unimportant = 10, threshold = -10, tradeoff_param = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run collapsing flame efore dropping important covariates\n",
    "researly = run_mpbit(df, holdout, range(15), [2]*15, covs_unimportant=10, threshold =-10, tradeoff_param = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(res_genearly, open('411genendrestestearly', 'wb'))\n",
    "pickle.dump(researly, open('411colendrestestearly', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get true and estimated cates for matched units\n",
    "truth_liste = []\n",
    "pred_liste = []\n",
    "count = 0\n",
    "av_err_catee = []\n",
    "aux_sizee = []\n",
    "for r in researly[1]:\n",
    "    count = count +1\n",
    "    tmp = pd.merge(r, ground_truth, on = list(set(range(5)) & set(r.columns) ), how = 'left')\n",
    "    truth_liste = truth_liste + list(tmp['effect_y'])\n",
    "    pred_liste = pred_liste + list(tmp['effect_x'])\n",
    "    aux_sizee = aux_sizee + list(tmp['size'])\n",
    "\n",
    "\n",
    "truth_list_gene = []\n",
    "pred_list_gene = []\n",
    "\n",
    "aux_size_gene = []\n",
    "for r_gen in res_genearly[1]:\n",
    "    tmp_gen = pd.merge(r_gen, ground_truth, on = list(set(range(5)) & set(r_gen.columns) ), how = 'left')\n",
    "    truth_list_gene = truth_list_gene + list(tmp_gen['effect_y'])\n",
    "    pred_list_gene = pred_list_gene + list(tmp_gen['effect_x'])\n",
    "    aux_size_gene = aux_size_gene + list(tmp_gen['size'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the true and estimated cates : data to be used in R for plots\n",
    "\n",
    "cateDF1 = pd.DataFrame()\n",
    "cateDF1['effect'] = pred_liste\n",
    "cateDF1['cate'] = ['estimated']*len(pred_liste)\n",
    "cateDF1['method'] = ['collapsing FLAME']*len(pred_liste)\n",
    "\n",
    "\n",
    "cateDF2 = pd.DataFrame()\n",
    "cateDF2['effect'] = truth_liste\n",
    "cateDF2['cate'] = ['true']*len(truth_liste)\n",
    "cateDF2['method'] = ['collapsing FLAME']*len(truth_liste)\n",
    "\n",
    "cateDF3 = pd.DataFrame()\n",
    "cateDF3['effect'] = pred_list_gene\n",
    "cateDF3['cate'] = ['estimated']*len(pred_list_gene)\n",
    "cateDF3['method'] = ['generic FLAME']*len(pred_list_gene)\n",
    "\n",
    "\n",
    "cateDF4 = pd.DataFrame()\n",
    "cateDF4['effect'] = truth_list_gene\n",
    "cateDF4['cate'] = ['true']*len(truth_list_gene)\n",
    "cateDF4['method'] = ['generic FLAME']*len(truth_list_gene)\n",
    "\n",
    "cate = pd.concat([cateDF1, cateDF2, cateDF3, cateDF4])\n",
    "cate_col = pd.concat([cateDF1, cateDF2])\n",
    "cate_gen = pd.concat([cateDF3, cateDF4])\n",
    "\n",
    "cate_gen.to_csv('cate411genearlytest.csv')\n",
    "cate_col.to_csv('cate411colearlytest.csv')\n",
    "\n",
    "cate.to_csv('cate411earlytest.csv')\n",
    "\n",
    "\n",
    "\n",
    "effect_col = pd.DataFrame()\n",
    "effect_col['pred'] = pred_liste\n",
    "effect_col['true'] = truth_liste\n",
    "effect_col['size'] = aux_sizee\n",
    "\n",
    "effect_col['method'] = ['collapsing FLAME']*len(truth_liste)\n",
    "\n",
    "\n",
    "effect_col.to_csv('effect411earlycoltest.csv')\n",
    "\n",
    "effect_gen = pd.DataFrame()\n",
    "effect_gen['pred'] = pred_list_gene\n",
    "effect_gen['true'] = truth_list_gene\n",
    "effect_gen['method'] = ['generic FLAME']*len(truth_list_gene)\n",
    "effect_gen['size'] = aux_size_gene\n",
    "\n",
    "\n",
    "effect = pd.concat([effect_gen, effect_col])\n",
    "effect_gen.to_csv('effect411earlygentest.csv')\n",
    "\n",
    "effect.to_csv('effect411earlytest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
